{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module allows you to train RNet with your custom dataset.\n",
    "To train RNet with your custom dataset, simply change the images inside the data/train and data/val folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install albumentations==0.4.6\n",
    "!pip install natsort\n",
    "!pip install opencv-python\n",
    "import platform\n",
    "if platform.python_version() >= \"3.10\":\n",
    "    import glob\n",
    "else:\n",
    "    %pip install glob2\n",
    "    import glob2 as glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils.model import RNet\n",
    "from utils.utils import (\n",
    "    load_checkpoint,\n",
    "    save_checkpoint,\n",
    "    get_loaders,\n",
    "    get_test_loader,\n",
    "    check_accuracy,\n",
    "    save_predictions_as_imgs,\n",
    ")\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import torchvision\n",
    "import re\n",
    "from torchvision import transforms\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters, you can change learning_rate, batch size, num_epochs, num_workers, image height and width, pin_memory as you wish\n",
    "# If you are going to test RNet with pre-trained model, set LOAD_MODEL = True\n",
    "# If you are going to train RNet by yourself, set LOAD_MODEL = False\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 5\n",
    "NUM_WORKERS = 4\n",
    "IMAGE_HEIGHT = 80  # 720 originally\n",
    "IMAGE_WIDTH = 120  # 1280 originally\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = True\n",
    "TRAIN_IMG_DIR = \"data/train\"\n",
    "TRAIN_MASK_DIR = \"data/val\"\n",
    "VAL_IMG_DIR = \"data/train\"\n",
    "VAL_MASK_DIR = \"data/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function\n",
    "def train_fn(loader, model, optimizer, loss_fn, scaler):\n",
    "    loop = tqdm(loader)\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(loop):\n",
    "        data = data.to(DEVICE)\n",
    "        targets = targets.float().unsqueeze(1).to(DEVICE)\n",
    "\n",
    "        # Forward\n",
    "        with torch.cuda.amp.autocast():\n",
    "          predictions = model(data)\n",
    "          loss = loss_fn(predictions, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update tqdm loop\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# Main function for starting the training\n",
    "# Training will start only if you set LOAD_MODEL = False\n",
    "def main():\n",
    "    train_transform = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Rotate(limit=35, p=1.0),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.1),\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0],\n",
    "                std=[1.0, 1.0, 1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    val_transforms = A.Compose(\n",
    "        [\n",
    "            A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),\n",
    "            A.Normalize(\n",
    "                mean=[0.0, 0.0, 0.0],\n",
    "                std=[1.0, 1.0, 1.0],\n",
    "                max_pixel_value=255.0,\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model = RNet(in_channels=3, out_channels=1).to(DEVICE)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_loader, val_loader = get_loaders(\n",
    "        TRAIN_IMG_DIR,\n",
    "        TRAIN_MASK_DIR,\n",
    "        VAL_IMG_DIR,\n",
    "        VAL_MASK_DIR,\n",
    "        BATCH_SIZE,\n",
    "        train_transform,\n",
    "        val_transforms,\n",
    "        NUM_WORKERS,\n",
    "        PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(torch.load(\"model/checkpoint.pth\"), model)\n",
    "    else:\n",
    "      scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "      for epoch in range(NUM_EPOCHS):\n",
    "          print(f\"Epoch: {epoch+1}/{NUM_EPOCHS}\")\n",
    "          train_fn(train_loader, model, optimizer, loss_fn, scaler)\n",
    "\n",
    "          # Save model\n",
    "          checkpoint = {\n",
    "              \"state_dict\": model.state_dict(),\n",
    "              \"optimizer\": optimizer.state_dict()\n",
    "          }\n",
    "          save_checkpoint(model)\n",
    "\n",
    "          # Check accuracy\n",
    "          if epoch == 0:\n",
    "            pass\n",
    "          else:\n",
    "            check_accuracy(val_loader, model, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
